import torch
from PIL import Image
import os
import cv2 # For image manipulation and cropping
import numpy as np
from bs4 import BeautifulSoup # For parsing hOCR
import re # For regex in hOCR parsing
from transformers import TrOCRProcessor, VisionEncoderDecoderModel
import base64
import tempfile
import subprocess # For running Tesseract

class OCRManager:
    """
    Manages OCR inference using a fine-tuned TrOCR model.
    Processes images line by line based on hOCR data generated by Tesseract.
    """

    def __init__(self, model_path: str, tesseract_cmd: str = 'tesseract', device: str = None, tr_ocr_max_length: int = 128):
        """
        Initializes the OCRManager.

        Args:
            model_path (str): Path to the directory containing the fine-tuned TrOCR model and processor.
            tesseract_cmd (str): Command to execute Tesseract. Defaults to 'tesseract'.
                                 Assumes Tesseract is in the system PATH.
            device (str, optional): The device to run the model on ('cuda', 'cpu'). 
                                    If None, autodetects CUDA or defaults to CPU.
            tr_ocr_max_length (int): Max length for token generation by TrOCR model.
        """
        print(f"Initializing OCRManager with model path: {model_path}")
        try:
            self.processor = TrOCRProcessor.from_pretrained(model_path, use_fast=True)
            self.model = VisionEncoderDecoderModel.from_pretrained(model_path)
        except Exception as e:
            print(f"Error loading TrOCR model/processor from {model_path}: {e}")
            raise

        if device:
            self.device = device
        else:
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        self.model.to(self.device)
        self.model.eval() # Set model to evaluation mode

        self.tesseract_cmd = tesseract_cmd
        self.tr_ocr_max_length = tr_ocr_max_length
        print(f"OCRManager initialized. Model loaded on device: {self.device}")

    @staticmethod
    def _extract_bbox_from_hocr_title(title_str: str):
        match = re.search(r'bbox\s+(\d+)\s+(\d+)\s+(\d+)\s+(\d+)', title_str)
        if match:
            return [int(c) for c in match.groups()]
        return None

    @staticmethod
    def _order_points(pts: np.ndarray):
        rect = np.zeros((4, 2), dtype="float32")
        sorted_y = pts[np.argsort(pts[:, 1]), :]
        top_two = sorted_y[:2, :]
        bottom_two = sorted_y[2:, :]
        top_two = top_two[np.argsort(top_two[:, 0]), :]
        rect[0] = top_two[0]
        rect[1] = top_two[1]
        bottom_two = bottom_two[np.argsort(bottom_two[:, 0]), :]
        rect[3] = bottom_two[0]
        rect[2] = bottom_two[1]
        return rect

    def _get_oriented_line_crop(self, image_cv: np.ndarray, hocr_line_bbox: list):
        if image_cv is None:
            # print(f"Warning: Input image_cv is None for bbox {hocr_line_bbox}")
            return None
        
        x1_h, y1_h, x2_h, y2_h = hocr_line_bbox
        _x1, _x2 = min(x1_h, x2_h), max(x1_h, x2_h)
        _y1, _y2 = min(y1_h, y2_h), max(y1_h, y2_h)
        x1, y1, x2, y2 = _x1, _y1, _x2, _y2

        if not (x2 > x1 and y2 > y1):
            # print(f"Warning: Invalid hOCR bbox for crop: {hocr_line_bbox}")
            return None
        
        img_h, img_w = image_cv.shape[:2]
        x1 = max(0, x1)
        y1 = max(0, y1)
        x2 = min(img_w - 1, x2)
        y2 = min(img_h - 1, y2)

        if not (x2 > x1 and y2 > y1):
            return None

        rect_pts = np.array([[x1, y1], [x2, y1], [x2, y2], [x1, y2]], dtype="float32")
        min_area_rect = cv2.minAreaRect(rect_pts)
        box_cv = cv2.boxPoints(min_area_rect)
        src_pts = self._order_points(box_cv)

        (tl, tr, br, bl) = src_pts
        width_a = np.linalg.norm(br - bl)
        width_b = np.linalg.norm(tr - tl)
        max_width = max(int(width_a), int(width_b))

        height_a = np.linalg.norm(tr - br)
        height_b = np.linalg.norm(tl - bl)
        max_height = max(int(height_a), int(height_b))

        if max_width <= 0 or max_height <= 0:
            y1_s, y2_s = int(y1), int(y2)
            x1_s, x2_s = int(x1), int(x2)
            if y2_s > y1_s and x2_s > x1_s:
                return image_cv[y1_s:y2_s, x1_s:x2_s]
            return None

        dst_pts = np.array([[0,0], [max_width-1,0], [max_width-1,max_height-1], [0,max_height-1]], dtype="float32")
        M = cv2.getPerspectiveTransform(src_pts, dst_pts)
        warped = cv2.warpPerspective(image_cv, M, (max_width, max_height))
        return warped

    def _generate_hocr_file(self, image_file_path: str, hocr_output_path_prefix: str) -> str:
        """
        Generates an hOCR file for the given image using Tesseract.

        Args:
            image_file_path (str): Path to the input image file.
            hocr_output_path_prefix (str): Prefix for the output hOCR file (without .hocr extension).
                                           The .hocr extension will be added.
        
        Returns:
            str: Path to the generated hOCR file.
        
        Raises:
            RuntimeError: If Tesseract command fails.
        """
        hocr_file_path = f"{hocr_output_path_prefix}.hocr"
        command = [
            self.tesseract_cmd,
            image_file_path,
            hocr_output_path_prefix, # Tesseract appends .hocr to this basename
            'hocr' 
        ]
        try:
            # print(f"Running Tesseract: {' '.join(command)}")
            process = subprocess.run(command, capture_output=True, text=True, check=True, timeout=60) # Added timeout
            # print(f"Tesseract stdout: {process.stdout}")
            # print(f"Tesseract stderr: {process.stderr}")
            if not os.path.exists(hocr_file_path):
                 raise RuntimeError(f"Tesseract ran but HOCR file not found at {hocr_file_path}. Stderr: {process.stderr}")
            return hocr_file_path
        except subprocess.CalledProcessError as e:
            error_message = f"Tesseract execution failed with error code {e.returncode}.\n" \
                            f"Command: {' '.join(e.cmd)}\n" \
                            f"Stdout: {e.stdout}\n" \
                            f"Stderr: {e.stderr}"
            print(error_message)
            raise RuntimeError(error_message) from e
        except subprocess.TimeoutExpired as e:
            error_message = f"Tesseract execution timed out after {e.timeout} seconds.\n" \
                            f"Command: {' '.join(e.cmd)}"
            print(error_message)
            raise RuntimeError(error_message) from e
        except Exception as e:
            print(f"An unexpected error occurred during Tesseract execution: {e}")
            raise RuntimeError(f"An unexpected error occurred during Tesseract execution: {e}") from e


    def _ocr_single_image_from_file(self, image_path: str, hocr_file_path: str) -> str:
        """
        Internal method to perform OCR on a single image file using its hOCR data.
        """
        try:
            full_image_cv = cv2.imread(image_path)
            if full_image_cv is None:
                print(f"Error: Could not read image at {image_path} with OpenCV.")
                return ""
        except Exception as e:
            print(f"Error loading image {image_path} with OpenCV: {e}")
            return ""

        try:
            with open(hocr_file_path, 'r', encoding='utf-8') as hf:
                soup = BeautifulSoup(hf, 'lxml-xml') # Using lxml parser
        except FileNotFoundError:
            print(f"Error: hOCR file not found at {hocr_file_path}.")
            return ""
        except Exception as e:
            print(f"Error reading or parsing hOCR file {hocr_file_path}: {e}")
            return ""

        line_elements = soup.find_all('span', class_=['ocr_line', 'ocrx_line'])
        if not line_elements:
            # print(f"No text lines found in hOCR file: {hocr_file_path}.")
            return ""

        detected_lines = []
        for line_elem in line_elements:
            title = line_elem.get('title', '')
            hocr_bbox = self._extract_bbox_from_hocr_title(title)
            if not hocr_bbox:
                continue

            cropped_line_cv = self._get_oriented_line_crop(full_image_cv, hocr_bbox)
            if cropped_line_cv is None or cropped_line_cv.size == 0:
                continue
            
            try:
                cropped_line_pil = Image.fromarray(cv2.cvtColor(cropped_line_cv, cv2.COLOR_BGR2RGB)).convert("RGB")
            except Exception as e:
                # print(f"Error converting OpenCV crop to PIL Image: {e}")
                continue

            try:
                pixel_values = self.processor(images=cropped_line_pil, return_tensors="pt").pixel_values.to(self.device)
            except Exception as e:
                # print(f"Error processing line with TrOCR processor: {e}")
                continue
            
            try:
                with torch.no_grad():
                    generated_ids = self.model.generate(pixel_values, max_length=self.tr_ocr_max_length)
                
                generated_text_list = self.processor.batch_decode(generated_ids, skip_special_tokens=True)
                if generated_text_list:
                    line_text = generated_text_list[0]
                    detected_lines.append((hocr_bbox[1], line_text))
            except Exception as e:
                # print(f"Error during model generation or decoding for line: {e}")
                continue
        
        detected_lines.sort(key=lambda item: item[0])
        return "\n".join([item[1] for item in detected_lines])

    def predict_batch(self, instances: list) -> dict:
        """
        Processes a batch of images provided as base64 encoded strings.

        Args:
            instances (list): A list of dictionaries, where each dictionary has a 'b64' key 
                              containing a base64 encoded JPEG image string. torch
                              Example: [{"key": 0, "b64": "BASE64_IMAGE_DATA"}, ...]

        Returns:
            dict: A dictionary with a "predictions" key, containing a list of
                  transcribed text strings, in the same order as the input instances.
                  Example: {"predictions": ["text1", "text2", ...]}
        """
        predictions = []
        for i, instance_data in enumerate(instances):
            b64_string = instance_data.get("b64")
            # instance_key = instance_data.get("key", f"item_{i}") # Key for logging if needed

            if not b64_string:
                print(f"Warning: Missing 'b64' data for instance {i}. Skipping.")
                predictions.append("") # Append empty string for missing data to maintain order
                continue

            temp_image_file = None
            temp_hocr_prefix = None
            hocr_file_path = None
            
            try:
                # Decode base64 image
                try:
                    image_bytes = base64.b64decode(b64_string)
                    # Convert bytes to OpenCV image
                    nparr = np.frombuffer(image_bytes, np.uint8)
                    img_cv = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
                    if img_cv is None:
                        raise ValueError("cv2.imdecode returned None. Invalid image data or format.")
                except Exception as e:
                    print(f"Error decoding base64 string or loading image for instance {i}: {e}")
                    predictions.append("") 
                    continue

                # Create a temporary file for the image (Tesseract needs a file path)
                # Suffix is important for Tesseract to recognize format, e.g., .jpg, .png
                with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as tf_img:
                    cv2.imwrite(tf_img.name, img_cv) # Save the OpenCV image to the temp file
                    temp_image_file = tf_img.name
                
                # Create a temporary path prefix for hOCR output
                with tempfile.NamedTemporaryFile(delete=True, prefix="hocr_out_") as tf_hocr_base:
                    temp_hocr_prefix = tf_hocr_base.name # Just using the name as a prefix

                # Generate hOCR file
                hocr_file_path = self._generate_hocr_file(temp_image_file, temp_hocr_prefix)
                
                # Perform OCR on the temporary image file using its hOCR data
                transcript = self._ocr_single_image_from_file(temp_image_file, hocr_file_path)
                predictions.append(transcript)

            except RuntimeError as e: # Catch errors from _generate_hocr_file or other critical steps
                print(f"RuntimeError processing instance {i}: {e}")
                predictions.append("") # Append empty string on error
            except Exception as e:
                print(f"Unexpected error processing instance {i}: {e}")
                predictions.append("")
            finally:
                # Clean up temporary files
                if temp_image_file and os.path.exists(temp_image_file):
                    os.remove(temp_image_file)
                # hocr_file_path is temp_hocr_prefix + ".hocr"
                actual_hocr_file = f"{temp_hocr_prefix}.hocr" if temp_hocr_prefix else None
                if actual_hocr_file and os.path.exists(actual_hocr_file):
                    os.remove(actual_hocr_file)
        
        return {"predictions": predictions}

# Example Usage (for testing the class directly, not part of the Flask app)
if __name__ == '__main__':
    # --- Configuration for Standalone Test ---
    TEST_MODEL_PATH = "./trocr_finetuned_final_model"  # Path to your fine-tuned model directory
    PREPROCESSED_DATA_DIR = "../paddleocr_rec_data_prepared2" # Path to your preprocessed data
    SAMPLE_IMAGE_SUBDIR = "train_crops" # Or "val_crops"
    NUM_SAMPLE_IMAGES = 2 # Number of sample images to test from the directory

    # Helper function to read an image file and convert it to a base64 string
    def image_to_base64_string(file_path: str) -> str | None:
        try:
            with open(file_path, "rb") as image_file:
                img_byte = image_file.read()
            b64_string = base64.b64encode(img_byte).decode('utf-8')
            return b64_string
        except FileNotFoundError:
            print(f"Error: Image file not found at {file_path}")
            return None
        except Exception as e:
            print(f"Error converting image {file_path} to base64: {e}")
            return None

    # Check if model path exists
    if not os.path.exists(TEST_MODEL_PATH) or not os.path.isdir(TEST_MODEL_PATH):
        print(f"Error: Model path '{TEST_MODEL_PATH}' does not exist or is not a directory.")
        print("Please ensure your fine-tuned TrOCR model is present at this location,")
        print("or update TEST_MODEL_PATH to the correct path.")
        print("Skipping OCRManager standalone test.")
    # Check if preprocessed data path exists
    elif not os.path.exists(PREPROCESSED_DATA_DIR) or not os.path.isdir(PREPROCESSED_DATA_DIR):
        print(f"Error: Preprocessed data path '{PREPROCESSED_DATA_DIR}' does not exist or is not a directory.")
        print("Please ensure your preprocessed image data is present at this location.")
        print("Skipping OCRManager standalone test.")
    else:
        print(f"Standalone Test: Attempting to initialize OCRManager with model: {TEST_MODEL_PATH}")
        try:
            # Initialize OCRManager
            # You might need to specify the tesseract_cmd if it's not in your PATH
            # e.g., tesseract_cmd='/usr/bin/tesseract' or 'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'
            ocr_manager = OCRManager(model_path=TEST_MODEL_PATH)
            
            # Prepare test instances from actual image files
            sample_images_b64 = []
            images_dir = os.path.join(PREPROCESSED_DATA_DIR, SAMPLE_IMAGE_SUBDIR)

            if not os.path.exists(images_dir) or not os.path.isdir(images_dir):
                print(f"Error: Sample images directory '{images_dir}' does not exist.")
            else:
                print(f"Looking for sample images in: {images_dir}")
                image_files = [
                    f for f in os.listdir(images_dir)
                    if os.path.isfile(os.path.join(images_dir, f)) and \
                       f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))
                ]
                
                if not image_files:
                    print(f"No image files found in {images_dir}.")
                else:
                    print(f"Found {len(image_files)} images. Taking up to {NUM_SAMPLE_IMAGES} samples.")
                    for img_file in image_files[:NUM_SAMPLE_IMAGES]:
                        img_path = os.path.join(images_dir, img_file)
                        print(f"  Processing sample: {img_path}")
                        b64_str = image_to_base64_string(img_path)
                        if b64_str:
                            sample_images_b64.append({"path": img_path, "b64": b64_str})
            
            if not sample_images_b64:
                print("Failed to load any sample images for testing. Ensure images exist in the specified directory.")
            else:
                test_instances = []
                for i, item in enumerate(sample_images_b64):
                    test_instances.append({"key": f"real_img_{i}", "b64": item["b64"], "source_path": item["path"]})
                
                # Optionally, add an invalid case to test error handling
                test_instances.append({"key": "invalid_b64", "b64": "this_is_not_base64", "source_path": "N/A"})

                print(f"\nRunning predict_batch with {len(test_instances)} test instances (from real images and one invalid)...")
                results = ocr_manager.predict_batch(test_instances)
                
                print("\n--- Batch Prediction Results ---")
                predictions_list = results.get("predictions", [])
                for i, prediction in enumerate(predictions_list):
                    instance_key = test_instances[i].get('key', i)
                    instance_path = test_instances[i].get('source_path', 'N/A')
                    print(f"Instance Key: {instance_key} (Source: {instance_path})")
                    print(f"  Prediction: '{prediction[:200]}{'...' if len(prediction) > 200 else ''}'") # Print snippet
                print("--- End of Batch Prediction Results ---")

        except RuntimeError as e:
            print(f"RuntimeError during OCRManager standalone test: {e}")
            print("This might be due to Tesseract not being found or failing.")
            print("Ensure Tesseract is installed and accessible in your system PATH,")
            print("or provide the full path to 'tesseract_cmd' in OCRManager constructor.")
        except Exception as e:
            print(f"An unexpected error occurred during OCRManager standalone test: {e}")
            import traceback
            traceback.print_exc()

